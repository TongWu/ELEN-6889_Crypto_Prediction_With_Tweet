{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tweepy\n",
    "import config\n",
    "import pyspark\n",
    "import emoji\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_unixtime, date_format, col, avg, sum, to_timestamp\n",
    "from pyspark.sql.functions import concat, lit\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import udf\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.types import StringType\n",
    "import findspark\n",
    "findspark.init()\n",
    "import cryptocompare\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, date, time, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "v = CountVectorizer(stop_words='english')\n",
    "import csv\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"MyApp\").getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 1: get cryptocurrency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[['2023-04-22', 0.3961530029773712], ['2023-04-23', 0.3889999985694885], ['2023-04-24', 0.3839159905910492], ['2023-04-25', 0.3949190080165863], ['2023-04-26', 0.4014979898929596], ['2023-04-27', 0.40984299778938293], ['2023-04-28', 0.4049319922924042], ['2023-04-29', 0.40278398990631104], ['2023-04-30', 0.39735400676727295]]\n"
     ]
    }
   ],
   "source": [
    "# Fetch BTC trade raw data\n",
    "today = date.today()\n",
    "BTC_raw = yf.download('ADA-USD', start=today-timedelta(days=7), end=today) # BTC, ETH, XRP, ADA, DOGE\n",
    "# BTC_raw.columns = ['date', 'open_price', 'high', 'low', 'close_price', 'adj close', 'volume']\n",
    "\n",
    "# reset index and move Date column to the first column\n",
    "BTC_raw = BTC_raw.reset_index().rename(columns={'Date': 'date'})\n",
    "BTC_raw = BTC_raw.loc[:, ['date', 'Close']]\n",
    "BTC_raw.head()\n",
    "\n",
    "l = len(BTC_raw[\"date\"])\n",
    "a = []\n",
    "for n in range(l):\n",
    "    data = [str(BTC_raw[\"date\"][n])[0:10], float(BTC_raw[\"Close\"][n])]\n",
    "    a.append(data)\n",
    "    \n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+\n",
      "|      date|        close price|\n",
      "+----------+-------------------+\n",
      "|2023-04-23| 0.3889999985694885|\n",
      "|2023-04-24| 0.3839159905910492|\n",
      "|2023-04-25| 0.3949190080165863|\n",
      "|2023-04-26| 0.4014979898929596|\n",
      "|2023-04-27|0.40984299778938293|\n",
      "|2023-04-28| 0.4049319922924042|\n",
      "|2023-04-29|0.40278398990631104|\n",
      "+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "day_price_data = spark.createDataFrame(a,[\"date\", \"close price\"])\n",
    "\n",
    "day_price_data.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2: get twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching twitter data...\n",
      "total twitter data: 7495\n"
     ]
    }
   ],
   "source": [
    "# Set up Twitter API credentials\n",
    "consumer_key = config.API_KEY\n",
    "consumer_secret= config.API_SECRET\n",
    "access_token= config.ACCESS_TOKEN\n",
    "access_token_secret = config.ACCESS_TOKEN_SECRET\n",
    "\n",
    "# Authenticate with Twitter API\n",
    "auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "\n",
    "# Query Twitter API for tweets\n",
    "data = tweepy.Cursor(api.search_tweets, q=\"Dogecoin OR DOGE\", until=\"2023-04-30 00:00:00\", lang=\"en\", count=100).items(8000)\n",
    "\n",
    "# Create an empty list to store the processed data\n",
    "processed_data_list = []\n",
    "\n",
    "print(\"fetching twitter data...\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        tweet = data.next()\n",
    "            \n",
    "        user_date = tweet.created_at\n",
    "        \n",
    "        #user_text = emoji.replace_emoji(tweet.text, replace=\"\")\n",
    "        user_text = tweet.text\n",
    "        final_data = [user_date, user_text]   \n",
    "            \n",
    "        processed_data_list.append(final_data)\n",
    "      \n",
    "    except StopIteration:\n",
    "        break\n",
    "\n",
    "print(\"total twitter data:\", len(processed_data_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis model \n",
    "\n",
    "analyzer=SentimentIntensityAnalyzer()\n",
    "def get_vader_score(sentence): \n",
    "    compound=analyzer.polarity_scores(sentence)['compound']\n",
    "    if compound > 0.05: \n",
    "        return ['positive',compound]\n",
    "    elif (compound >= -0.05) and (compound <=0.05): \n",
    "        return ['neutral',compound]\n",
    "    else: \n",
    "        return ['negative',compound]\n",
    "\n",
    "def vader_sentiment(X):\n",
    "  vader_result=get_vader_score(X)[0]#X.apply(lambda x: get_vader_score(x)[0])\n",
    "  vader_score = get_vader_score(X)[1]#X.apply(lambda x: get_vader_score(x)[1])\n",
    "  #vader_score_total = np.mean(vader_score)\n",
    "  return vader_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove emoji\n",
    "def remove_emoji(col):\n",
    "  result = emoji.replace_emoji(col, replace=\"\")\n",
    "  return result\n",
    "\n",
    "\n",
    "# Create a DataFrame from the processed data list\n",
    "twitter_data = spark.createDataFrame(processed_data_list, [\"date\", \"text\"])\n",
    "\n",
    "# start PySpark transform #####################################################################\n",
    "\n",
    "clean_udf = F.UserDefinedFunction(remove_emoji, T.StringType())\n",
    "tweets_df_cleaned = twitter_data.withColumn(\"text\", clean_udf(\"text\"))\n",
    "\n",
    "# remove mention \n",
    "cleaned_twitter_data = twitter_data.withColumn(\"text\", regexp_replace('text', \"@\\s*[A-Za-z0-9_]+\", ''))\n",
    "cleaned_twitter_data = cleaned_twitter_data.withColumn(\"text\", regexp_replace(\"text\", \"#\\s*[A-Za-z0-9_]+\", \"\"))\n",
    "# remove retweet\n",
    "cleaned_twitter_data = cleaned_twitter_data.withColumn(\"text\", regexp_replace('text', \"RT : \", ''))\n",
    "\n",
    "# remove links\n",
    "cleaned_twitter_data = cleaned_twitter_data.withColumn('text', regexp_replace('text', r\"http\\S+\", ''))\n",
    "cleaned_twitter_data = cleaned_twitter_data.withColumn('text', regexp_replace('text', r\"www.\\S+\", ''))\n",
    "\n",
    "# remove next line\n",
    "cleaned_twitter_data = cleaned_twitter_data.withColumn(\"text\", regexp_replace(\"text\", r\"\\n\", \"\"))\n",
    "\n",
    "cleaned_twitter_data = cleaned_twitter_data.withColumn('text', regexp_replace('text', '\\s+', ' '))\n",
    "\n",
    "cleaned_twitter_data = cleaned_twitter_data.select(col('date'), col('text'))\n",
    "\n",
    "# put sentiment analysis here\n",
    "\n",
    "# model 1\n",
    "\n",
    "vader_sentiment_udf = F.UserDefinedFunction(vader_sentiment, T.FloatType())\n",
    "vader_sentiment_twitter_data = cleaned_twitter_data.withColumn(\"text\", vader_sentiment_udf(\"text\"))\n",
    "\n",
    "# calculate average\n",
    "\n",
    "vader_sentiment_twitter_data = vader_sentiment_twitter_data.groupBy(date_format(col(\"date\"), \"yyyy-MM-dd\").alias(\"date\"))\n",
    "vader_sentiment_twitter_data = vader_sentiment_twitter_data.agg(avg(\"text\").alias(\"avg_value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final = vader_sentiment_twitter_data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_sentiment_twitter_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save csv\n",
    "\n",
    "with open(\"C:\\\\Users\\\\ee527\\\\Desktop\\\\DOGE.csv\", 'w', newline='') as f:\n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "    \n",
    "    for row in final:\n",
    "        \n",
    "        # write a row to the csv file\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 3: integrate two data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_sentiment_twitter_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------------------+\n",
      "|      date|           avg_value|        close price|\n",
      "+----------+--------------------+-------------------+\n",
      "|2023-04-29|  0.1506818802216289|0.40278398990631104|\n",
      "|2023-04-28|0.038404610113824726| 0.4049319922924042|\n",
      "|2023-04-27|-0.00744525705840...|0.40984299778938293|\n",
      "|2023-04-26| 0.14644978303556977| 0.4014979898929596|\n",
      "|2023-04-25|  0.2427375049376378| 0.3949190080165863|\n",
      "|2023-04-24|  0.3055099020250612| 0.3839159905910492|\n",
      "|2023-04-23| 0.04314303423794154| 0.3889999985694885|\n",
      "+----------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_df = vader_sentiment_twitter_data.join(day_price_data,\"date\",\"left\")\n",
    "\n",
    "merged_df = merged_df.dropna()\n",
    "\n",
    "merged_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
