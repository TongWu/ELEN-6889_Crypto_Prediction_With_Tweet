{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import config\n",
    "import pyspark\n",
    "import emoji\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_unixtime\n",
    "from pyspark.sql.functions import concat, lit\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import udf\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.types import StringType\n",
    "import findspark\n",
    "findspark.init()\n",
    "import cryptocompare\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"MyApp\").getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 1: get cryptocurrency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ticker symbol and other details\n",
    "ticker_symbol = 'BTC'\n",
    "currency = 'USD'\n",
    "limit_value = 2000  # max value \n",
    "exchange_name = 'CCCAGG'\n",
    "data_before_timestamp = datetime(2023, 4, 27, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the raw price data\n",
    "raw_price_data = \\\n",
    "    cryptocompare.get_historical_price_hour(\n",
    "        ticker_symbol,\n",
    "        currency,\n",
    "        limit=limit_value,\n",
    "        exchange=exchange_name,\n",
    "        toTs=data_before_timestamp\n",
    "    )\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"PriceData\").getOrCreate()\n",
    "\n",
    "# Convert the list of dictionaries to a PySpark RDD\n",
    "raw_price_data = spark.sparkContext.parallelize(raw_price_data)\n",
    "\n",
    "hourly_price_data = spark.createDataFrame(raw_price_data)\n",
    "\n",
    "# Convert the 'time' column to a timestamp column and set it as the index\n",
    "hourly_price_data = hourly_price_data.withColumn(\"time\", from_unixtime(col(\"time\")))\n",
    "\n",
    "hourly_price_data = hourly_price_data.select(col('time'), col('close'))\n",
    "\n",
    "hourly_price_data.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2: get twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Twitter API credentials\n",
    "consumer_key = config.API_KEY\n",
    "consumer_secret= config.API_SECRET\n",
    "access_token= config.ACCESS_TOKEN\n",
    "access_token_secret = config.ACCESS_TOKEN_SECRET\n",
    "\n",
    "# Authenticate with Twitter API\n",
    "auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "\n",
    "# Query Twitter API for tweets\n",
    "data = tweepy.Cursor(api.search_tweets, q=\"bitcoin\", until=\"2023-04-28 00:00:00\", lang=\"en\", count=100).items(9000)\n",
    "\n",
    "# Create an empty list to store the processed data\n",
    "processed_data_list = []\n",
    "\n",
    "print(\"fetching twitter data...\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        tweet = data.next()\n",
    "            \n",
    "        user_date = tweet.created_at\n",
    "        \n",
    "        #user_text = emoji.replace_emoji(tweet.text, replace=\"\")\n",
    "        user_text = tweet.text\n",
    "        final_data = [user_date, user_text]   \n",
    "            \n",
    "        processed_data_list.append(final_data)\n",
    "      \n",
    "    except StopIteration:\n",
    "        break\n",
    "\n",
    "print(\"total twitter data:\", len(processed_data_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove emoji\n",
    "def remove_emoji(col):\n",
    "  result = emoji.replace_emoji(col, replace=\"\")\n",
    "  return result\n",
    "\n",
    "\n",
    "# Create a DataFrame from the processed data list\n",
    "twitter_data = spark.createDataFrame(processed_data_list, [\"time\", \"text\"])\n",
    "\n",
    "# start PySpark transform #####################################################################\n",
    "print(\"start spark transform...\")\n",
    "\n",
    "clean_udf = F.UserDefinedFunction(remove_emoji, T.StringType())\n",
    "tweets_df_cleaned = twitter_data.withColumn(\"text\", clean_udf(\"text\"))\n",
    "\n",
    "\n",
    "# remove mention \n",
    "cleaned_twitter_data = twitter_data.withColumn(\"text\", regexp_replace('text', \"@\\s*[A-Za-z0-9_]+\", ''))\n",
    "cleaned_twitter_data = cleaned_twitter_data.withColumn(\"text\", regexp_replace(\"text\", \"#\\s*[A-Za-z0-9_]+\", \"\"))\n",
    "# remove retweet\n",
    "cleaned_twitter_data = cleaned_twitter_data.withColumn(\"text\", regexp_replace('text', \"RT : \", ''))\n",
    "\n",
    "# remove links\n",
    "cleaned_twitter_data = cleaned_twitter_data.withColumn('text', regexp_replace('text', r\"http\\S+\", ''))\n",
    "cleaned_twitter_data = cleaned_twitter_data.withColumn('text', regexp_replace('text', r\"www.\\S+\", ''))\n",
    "\n",
    "# remove next line\n",
    "cleaned_twitter_data = cleaned_twitter_data.withColumn(\"text\", regexp_replace(\"text\", r\"\\n\", \"\"))\n",
    "\n",
    "cleaned_twitter_data = cleaned_twitter_data.withColumn('text', regexp_replace('text', '\\s+', ' '))\n",
    "\n",
    "cleaned_twitter_data = cleaned_twitter_data.select(col('time'), col('text'))\n",
    "\n",
    "cleaned_twitter_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do entiment Analysis here\n",
    "\n",
    "\n",
    "def upper_case(s):\n",
    "    return s.upper()\n",
    "\n",
    "upper_case_udf = udf(lambda x: upper_case(x), StringType())\n",
    "\n",
    "df = df.withColumn(\"new_column\", upper_case_udf(df[\"old_column\"]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 3: integrate two data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = cleaned_twitter_data.union(hourly_price_data)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 4: start predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
