{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import config\n",
    "import pyspark\n",
    "import emoji\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_unixtime\n",
    "from pyspark.sql.functions import concat, lit\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import udf\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.types import StringType\n",
    "import findspark\n",
    "findspark.init()\n",
    "import cryptocompare\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "# remove emoji\n",
    "def remove_emoji(col):\n",
    "  result = emoji.replace_emoji(col, replace=\"\")\n",
    "  return result\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"MyApp\").getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 1: get cryptocurrency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ticker symbol and other details\n",
    "ticker_symbol = 'BTC'\n",
    "currency = 'USD'\n",
    "limit_value = 2000  # max value \n",
    "exchange_name = 'CCCAGG'\n",
    "data_before_timestamp = datetime(2023, 4, 27, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+\n",
      "|               time|   close|\n",
      "+-------------------+--------+\n",
      "|2023-02-02 15:00:00|23861.61|\n",
      "|2023-02-02 16:00:00|23501.65|\n",
      "|2023-02-02 17:00:00|23567.87|\n",
      "|2023-02-02 18:00:00| 23470.8|\n",
      "|2023-02-02 19:00:00|23563.06|\n",
      "|2023-02-02 20:00:00|23564.12|\n",
      "|2023-02-02 21:00:00| 23485.3|\n",
      "|2023-02-02 22:00:00|23537.51|\n",
      "|2023-02-02 23:00:00|23521.08|\n",
      "|2023-02-03 00:00:00| 23529.4|\n",
      "|2023-02-03 01:00:00|23520.61|\n",
      "|2023-02-03 02:00:00| 23458.2|\n",
      "|2023-02-03 03:00:00|23425.23|\n",
      "|2023-02-03 04:00:00|23422.44|\n",
      "|2023-02-03 05:00:00|23434.66|\n",
      "|2023-02-03 06:00:00|23536.05|\n",
      "|2023-02-03 07:00:00|23528.95|\n",
      "|2023-02-03 08:00:00|23343.91|\n",
      "|2023-02-03 09:00:00|23518.73|\n",
      "|2023-02-03 10:00:00|23608.44|\n",
      "+-------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fetch the raw price data\n",
    "raw_price_data = \\\n",
    "    cryptocompare.get_historical_price_hour(\n",
    "        ticker_symbol,\n",
    "        currency,\n",
    "        limit=limit_value,\n",
    "        exchange=exchange_name,\n",
    "        toTs=data_before_timestamp\n",
    "    )\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"PriceData\").getOrCreate()\n",
    "\n",
    "# Convert the list of dictionaries to a PySpark RDD\n",
    "raw_price_data = spark.sparkContext.parallelize(raw_price_data)\n",
    "\n",
    "hourly_price_data = spark.createDataFrame(raw_price_data)\n",
    "\n",
    "# Convert the 'time' column to a timestamp column and set it as the index\n",
    "hourly_price_data = hourly_price_data.withColumn(\"time\", from_unixtime(col(\"time\")))\n",
    "\n",
    "hourly_price_data = hourly_price_data.select(col('time'), col('close'))\n",
    "\n",
    "hourly_price_data.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2: get twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start spark transform\n",
      "+-------------------+--------------------+\n",
      "|               time|                text|\n",
      "+-------------------+--------------------+\n",
      "|2023-04-27 19:56:44|Monday morning, 1...|\n",
      "|2023-04-27 19:56:00|trade stats date ...|\n",
      "|2023-04-27 19:54:36|- BTC price: $29,...|\n",
      "|2023-04-27 19:47:59|Bitcoin Hunter ($...|\n",
      "|2023-04-27 19:47:05|[Blockchain Valle...|\n",
      "|2023-04-27 19:46:19|Bitcoin Hunter ($...|\n",
      "|2023-04-27 19:44:16|[Star Daily News]...|\n",
      "|2023-04-27 19:43:41|1: Bitcoin price ...|\n",
      "|2023-04-27 19:43:34|Bitcoin Hunter ($...|\n",
      "|2023-04-27 19:41:30|- BTC price: $29,...|\n",
      "+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up Twitter API credentials\n",
    "consumer_key = config.API_KEY\n",
    "consumer_secret= config.API_SECRET\n",
    "access_token= config.ACCESS_TOKEN\n",
    "access_token_secret = config.ACCESS_TOKEN_SECRET\n",
    "\n",
    "# Authenticate with Twitter API\n",
    "auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "\n",
    "# Query Twitter API for tweets\n",
    "data = tweepy.Cursor(api.search_tweets, q=\"bitcoin\", until=\"2023-04-28 00:00:00\", lang=\"en\", count=1).items(10)\n",
    "\n",
    "# Create an empty list to store the processed data\n",
    "processed_data_list = []\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        tweet = data.next()\n",
    "            \n",
    "        user_date = tweet.created_at\n",
    "        \n",
    "        #user_text = emoji.replace_emoji(tweet.text, replace=\"\")\n",
    "        user_text = tweet.text\n",
    "        final_data = [user_date, user_text]   \n",
    "            \n",
    "        processed_data_list.append(final_data)\n",
    "      \n",
    "    except StopIteration:\n",
    "        break\n",
    "\n",
    "\n",
    "# Create a DataFrame from the processed data list\n",
    "twitter_data = spark.createDataFrame(processed_data_list, [\"time\", \"text\"])\n",
    "\n",
    "# start PySpark transform #####################################################################\n",
    "print(\"start spark transform\")\n",
    "\n",
    "clean_udf = F.UserDefinedFunction(remove_emoji, T.StringType())\n",
    "tweets_df_cleaned = twitter_data.withColumn(\"text\", clean_udf(\"text\"))\n",
    "\n",
    "\n",
    "# remove mention \n",
    "cleaned_twitter_data = twitter_data.withColumn(\"text\", regexp_replace('text', \"@\\s*[A-Za-z0-9_]+\", ''))\n",
    "cleaned_twitter_data = cleaned_twitter_data.withColumn(\"text\", regexp_replace(\"text\", \"#\\s*[A-Za-z0-9_]+\", \"\"))\n",
    "# remove retweet\n",
    "cleaned_twitter_data = cleaned_twitter_data.withColumn(\"text\", regexp_replace('text', \"RT : \", ''))\n",
    "\n",
    "# remove links\n",
    "cleaned_twitter_data = cleaned_twitter_data.withColumn('text', regexp_replace('text', r\"http\\S+\", ''))\n",
    "cleaned_twitter_data = cleaned_twitter_data.withColumn('text', regexp_replace('text', r\"www.\\S+\", ''))\n",
    "\n",
    "# remove next line\n",
    "cleaned_twitter_data = cleaned_twitter_data.withColumn(\"text\", regexp_replace(\"text\", r\"\\n\", \"\"))\n",
    "\n",
    "cleaned_twitter_data = cleaned_twitter_data.withColumn('text', regexp_replace('text', '\\s+', ' '))\n",
    "\n",
    "cleaned_twitter_data = cleaned_twitter_data.select(col('time'), col('text'))\n",
    "\n",
    "cleaned_twitter_data.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do entiment Analysis here\n",
    "\n",
    "\n",
    "def upper_case(s):\n",
    "    return s.upper()\n",
    "\n",
    "upper_case_udf = udf(lambda x: upper_case(x), StringType())\n",
    "\n",
    "df = df.withColumn(\"new_column\", upper_case_udf(df[\"old_column\"]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 3: integrate two data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|               time|                text|\n",
      "+-------------------+--------------------+\n",
      "|2023-04-27 19:56:44|Monday morning, 1...|\n",
      "|2023-04-27 19:56:00|trade stats date ...|\n",
      "|2023-04-27 19:54:36|- BTC price: $29,...|\n",
      "|2023-04-27 19:47:59|Bitcoin Hunter ($...|\n",
      "|2023-04-27 19:47:05|[Blockchain Valle...|\n",
      "|2023-04-27 19:46:19|Bitcoin Hunter ($...|\n",
      "|2023-04-27 19:44:16|[Star Daily News]...|\n",
      "|2023-04-27 19:43:41|1: Bitcoin price ...|\n",
      "|2023-04-27 19:43:34|Bitcoin Hunter ($...|\n",
      "|2023-04-27 19:41:30|- BTC price: $29,...|\n",
      "|2023-02-02 15:00:00|            23861.61|\n",
      "|2023-02-02 16:00:00|            23501.65|\n",
      "|2023-02-02 17:00:00|            23567.87|\n",
      "|2023-02-02 18:00:00|             23470.8|\n",
      "|2023-02-02 19:00:00|            23563.06|\n",
      "|2023-02-02 20:00:00|            23564.12|\n",
      "|2023-02-02 21:00:00|             23485.3|\n",
      "|2023-02-02 22:00:00|            23537.51|\n",
      "|2023-02-02 23:00:00|            23521.08|\n",
      "|2023-02-03 00:00:00|             23529.4|\n",
      "+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 将两个 DataFrame 合并为一个\n",
    "merged_df = cleaned_twitter_data.union(hourly_price_data)\n",
    "\n",
    "# 按照 time 字段进行分组和汇总\n",
    "grouped_df = merged_df.groupBy('time').agg({'field1': 'sum', 'field2': 'avg', ...})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 4: start predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
