{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taYOANKIqxGn"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import datetime\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def merge_sentimental_data(sentimental_data_file_path, XRP_data):\n",
    "  # Load sentimental data in csv\n",
    "  sentiment_data = pd.read_csv(sentimental_data_file_path).iloc[:, 1]\n",
    "  zeros = pd.DataFrame([0]*21)\n",
    "  sentiment_data = pd.concat([zeros, sentiment_data], ignore_index=True)\n",
    "  # Merge with XRP quant\n",
    "  merged_data = pd.concat([XRP_data, sentiment_data], axis=1)\n",
    "  num_rows = len(XRP_data)\n",
    "  new_data_adjusted = pd.DataFrame([0] * num_rows, index=XRP_data.index)\n",
    "  new_data_adjusted.iloc[-len(sentiment_data):] = sentiment_data.values\n",
    "  merged_data = pd.concat([XRP_data, new_data_adjusted], axis=1)\n",
    "  merged_data.columns = list(XRP_data.columns) + ['sentiment']\n",
    "  return merged_data"
   ],
   "metadata": {
    "id": "KFqAXsDiq8Ly"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "### The code below is for dataset that merge sentimental data ONLY\n",
    "### The code will be commented until the sentimental data is fetched\n",
    "def predict(num_days_to_predict, sentimental_data_file_path):\n",
    "    # Load model, prediction csv\n",
    "    model_path = './LSTM_model.h5'\n",
    "    model = load_model(model_path)\n",
    "    prediction_path = './prediction.csv'\n",
    "    prediction = pd.read_csv(prediction_path)\n",
    "    error = prediction.iloc[-1, 0] - prediction.iloc[-1, 1]\n",
    "    ### Fetch XRP-USD data BEGIN ###\n",
    "    ### CHANGE THIS TO THE FUNCTION USING PYSPARK ###\n",
    "    today = datetime.date.today()\n",
    "    XRP_quant = yf.download('XRP-USD', start=today-datetime.timedelta(days=365), end=today)\n",
    "    ### Fetch XRP-USD data END ###\n",
    "    new_df=XRP_quant.filter(['Adj Close'])\n",
    "    # Merge sentimental data\n",
    "    merged_data = merge_sentimental_data(sentimental_data_file_path, new_df)\n",
    "    # Create 30 window days slot\n",
    "    last_30_days = merged_data[-30:].values\n",
    "    last_30_days_price = merged_data['Adj Close'][-30:].values.reshape(-1, 1)\n",
    "    last_30_days_sentiment = merged_data['sentiment'][-30:].values.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler()\n",
    "    last_30_days_scaled_price = scaler.fit_transform(last_30_days_price)\n",
    "    sentiment_data = pd.read_csv(sentimental_data_file_path).iloc[:, 1]\n",
    "    sentiment_values = sentiment_data.values.reshape(-1, 1)\n",
    "    scaler_sentiment = MinMaxScaler()\n",
    "    scaled_sentiment = scaler_sentiment.fit_transform(sentiment_values)\n",
    "    last_30_days_scaled_sentiment = scaler_sentiment.transform(last_30_days_sentiment)\n",
    "    predictions = []\n",
    "    predicted_dates = []\n",
    "    # Predict price\n",
    "    for _ in range(num_days_to_predict):\n",
    "        offset = error*(0.5-0.03*_)\n",
    "        if (offset<0):\n",
    "          offset = 0\n",
    "        last_date = merged_data.index[-1]\n",
    "        X_test = []\n",
    "        X_test.append(np.hstack((last_30_days_scaled_price.flatten(), last_30_days_scaled_sentiment.flatten())))\n",
    "        X_test = np.array(X_test)\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "        pred_price = model.predict(X_test)\n",
    "        pred_price_unscaled = scaler.inverse_transform(pred_price)\n",
    "        predictions.append(pred_price_unscaled[0][0]+offset)\n",
    "        last_30_days_scaled_price = np.concatenate((last_30_days_scaled_price[1:], pred_price), axis=0)\n",
    "        predicted_date = last_date + datetime.timedelta(days=_+1)\n",
    "        predicted_dates.append(predicted_date)\n",
    "    # print(f\"Price of XRP-USD for the next {num_days_to_predict} trading days: {predictions}\")\n",
    "    output_text = f\"Price of XRP-USD for the next {num_days_to_predict} trading days: {predictions}\"\n",
    "    print(output_text)\n",
    "    file_name = f\"./public/XRP/Prediction_{num_days_to_predict}days.txt\"\n",
    "    with open(file_name, 'w') as file:\n",
    "      file.write(output_text)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(predicted_dates, predictions, marker='o', label='Predicted Prices')\n",
    "    ax.set(xlabel='Date', ylabel='XRP-USD Price', title=f'Predicted XRP-USD Prices for the Next {num_days_to_predict} Trading Days')\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "    ax.set_xlim(predicted_dates[0] - datetime.timedelta(days=2), predicted_dates[0] + datetime.timedelta(days=num_days_to_predict+3))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(f'/src/Components/XRP/Prediction_{num_days_to_predict}days', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "id": "4tka8jB5q9Ig"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sentimental_data_file_path = './XRP_vader.csv'\n",
    "predict(30, sentimental_data_file_path)"
   ],
   "metadata": {
    "id": "XhpbRv8gq-g6"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
